{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable Boosting Machine (EBM) for Earned Value Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation  dataset\n",
    "# Null model (5-rand) of comparison\n",
    "data=pd.read_csv('./montecarlo/simulation_EV0.75_5-rand.csv',index_col=0)\n",
    "data['critical_path']=data['critical_path'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresion models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection\n",
    "We use nested cross-validation with the null model (5-rand) simulation dataset for the backward regression problem DBAC~ {activity i's duration at 75%EV} i=1,...,8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reegression models\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from interpret.glassbox import ExplainableBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "seed=1123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBAC regression\n",
    "y=data.loc[:,'duration']\n",
    "X=data.loc[:,['duration@1','duration@2', 'duration@3','duration@4', 'duration@5','duration@6', 'duration@7','duration@8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer kfolds\n",
    "kfold = KFold(n_splits=5, random_state=seed,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save outer kfolds\n",
    "kfs=pd.DataFrame([],columns=['kn','type','i'])\n",
    "k=0\n",
    "for train_index, test_index in kfold.split(X):\n",
    "  p1=pd.DataFrame(train_index,columns=['i'])\n",
    "  p1['kn']=k\n",
    "  p1['type']='train'\n",
    "  p2=pd.DataFrame(test_index,columns=['i'])\n",
    "  p2['kn']=k\n",
    "  p2['type']='test'\n",
    "  p1=pd.concat([p1,p2],ignore_index=True)\n",
    "  kfs=pd.concat([kfs,p1],ignore_index=True)\n",
    "  k+=1\n",
    "kfs.reset_index(inplace=True,drop=True)\n",
    "kfs.to_csv('./data/regression_model_selection_kf_index.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load outer kfolds\n",
    "kfs=pd.read_csv('./data/regression_model_selection_kf_index.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results\n",
    "results = pd.DataFrame([['none',0,0]],columns=['model','kf','MSE']) # adding a null row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 0...\n",
      "running 1...\n",
      "running 2...\n",
      "running 3...\n",
      "running 4...\n"
     ]
    }
   ],
   "source": [
    "# ExplainableBoostingRegressor\n",
    "# https://interpret.ml/docs/python/api/ExplainableBoostingRegressor.html\n",
    "model='ExplainableBoostingR'\n",
    "k=0\n",
    "for train_index, test_index in kfold.split(X):\n",
    "  print('running %i...'%k)\n",
    "  # parameter optimization in the inner folds\n",
    "    # inner_bags: number of inner bags.\n",
    "    # max_leaves: maximum leaf nodes used in boosting.\n",
    "    # outer_bags: number of outer bags.\n",
    "  mdr = GridSearchCV(ExplainableBoostingRegressor(),param_grid={\"inner_bags\": np.linspace(0,6,3).astype('int'),\n",
    "                                                                 \"max_leaves\": np.linspace(1,3,3).astype('int')},n_jobs=6)    \n",
    "\n",
    "  mdr.fit(X.iloc[train_index,:], y.iloc[train_index])\n",
    "  \n",
    "  # score of the best model in the outer fold\n",
    "  results = pd.concat([results,pd.DataFrame([[model,k, mean_squared_error(y.iloc[test_index],mdr.best_estimator_.predict(X.iloc[test_index,:]))]],columns=['model','kf','MSE'])],ignore_index=True)\n",
    "  \n",
    "  k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('./data/regression_ebm_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "model='RFR'\n",
    "k=0\n",
    "for train_index, test_index in kfold.split(X):\n",
    "\n",
    "  # parameter optimization in the inner folds\n",
    "    # n_estimators: number of trees\n",
    "    # max_depth of the trees\n",
    "  mdr = GridSearchCV(RandomForestRegressor(),\n",
    "                    param_grid={\"n_estimators\": np.linspace(100,1000,5).astype('int'), \n",
    "                            \"max_depth\": np.linspace(1,10,5).astype('int')},\n",
    "                    n_jobs=6)  \n",
    "  mdr.fit(X.iloc[train_index,:], y.iloc[train_index])\n",
    "  \n",
    "  # score of the best model in the outer fold\n",
    "  results = pd.concat([results, pd.DataFrame([[model,k, \n",
    "        mean_squared_error(y.iloc[test_index],mdr.best_estimator_.predict(X.iloc[test_index,:]))]],columns=['model','kf','MSE'])],ignore_index=True)\n",
    "  k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('./data/regression_rf_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 0...\n",
      "running 1...\n",
      "running 2...\n",
      "running 3...\n",
      "running 4...\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingRegressor\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
    "model='GradientBoostingR'\n",
    "k=0\n",
    "for train_index, test_index in kfold.split(X):\n",
    "  print('running %i...'%k)\n",
    "  # parameter optimization in the inner folds\n",
    "    # n_estimators: number of  boosting stages\n",
    "    # max_depth of the regression estimators\n",
    "  mdr = GridSearchCV(GradientBoostingRegressor(),\n",
    "                    param_grid={\"n_estimators\": np.linspace(100,1000,5).astype('int'),  \n",
    "                                \"max_depth\": np.linspace(1,10,5).astype('int')},\n",
    "                    n_jobs=6)  \n",
    "  mdr.fit(X.iloc[train_index,:], y.iloc[train_index])\n",
    "  \n",
    "  # score of the best model in the outer fold\n",
    "  results = pd.concat([results, pd.DataFrame([[model,k, mean_squared_error(y.iloc[test_index],mdr.best_estimator_.predict(X.iloc[test_index,:]))]],columns=['model','kf','MSE'])],ignore_index=True)\n",
    "  k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('./data/regression_gb_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 0...\n",
      "running 1...\n",
      "running 2...\n",
      "running 3...\n",
      "running 4...\n"
     ]
    }
   ],
   "source": [
    "# AdaBoostRegressor\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html\n",
    "model='AdaBoostR'\n",
    "k=0\n",
    "for train_index, test_index in kfold.split(X):\n",
    "  print('running %i...'%k)\n",
    "  # parameter optimization in the inner folds\n",
    "    # n_estimators: maximum number of estimators at which boosting is terminated\n",
    "  mdr = GridSearchCV(AdaBoostRegressor(),\n",
    "                    param_grid={\"n_estimators\": np.linspace(100,1000,5).astype('int'),\n",
    "                                \"learning_rate\": np.linspace(0.1,1,5)},\n",
    "                    n_jobs=6)\n",
    "  mdr.fit(X.iloc[train_index,:], y.iloc[train_index])\n",
    "  \n",
    "  # score of the best model in the outer fold\n",
    "  results = pd.concat([results, pd.DataFrame([[model,k, mean_squared_error(y.iloc[test_index],mdr.best_estimator_.predict(X.iloc[test_index,:]))]],columns=['model','kf','MSE'])],ignore_index=True)\n",
    "  k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('./data/regression_ab_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 0...\n",
      "running 1...\n",
      "running 2...\n",
      "running 3...\n",
      "running 4...\n"
     ]
    }
   ],
   "source": [
    "# XGBRegressor\n",
    "# https://xgboost.readthedocs.io/en/stable/python/python_api.html#module-xgboost.sklearn\n",
    "model='XGBoostR'\n",
    "k=0\n",
    "for train_index, test_index in kfold.split(X):\n",
    "  print('running %i...'%k)\n",
    "  # parameter optimization in the inner folds\n",
    "    # n_estimators: number of gradient boosted trees\n",
    "    # max_depth: maximum tree depth for base learners\n",
    "  mdr = GridSearchCV(XGBRegressor(verbosity = 0),\n",
    "                    param_grid={\"n_estimators\": np.linspace(100,1000,5).astype('int'),  \n",
    "                                \"max_depth\": np.linspace(1,10,5).astype('int')},\n",
    "                    n_jobs=6)    \n",
    "  mdr.fit(X.iloc[train_index,:], y.iloc[train_index])\n",
    "  \n",
    "  # score of the best model in the outer fold\n",
    "  results = pd.concat([results, pd.DataFrame([[model,k, mean_squared_error(y.iloc[test_index],mdr.best_estimator_.predict(X.iloc[test_index,:]))]],columns=['model','kf','MSE'])],ignore_index=True)\n",
    "  k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('./data/regression_xgb_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results.drop(results[results.model=='none'].index,inplace=True)\n",
    "results.reset_index(inplace=True,drop=True)\n",
    "results.to_csv('./data/regression_model_selection_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "results=pd.read_csv('./data/regression_model_selection_results.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">MSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExplainableBoostingR</th>\n",
       "      <td>9.165603</td>\n",
       "      <td>0.183922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingR</th>\n",
       "      <td>9.192149</td>\n",
       "      <td>0.197236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFR</th>\n",
       "      <td>9.201881</td>\n",
       "      <td>0.170242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoostR</th>\n",
       "      <td>9.209953</td>\n",
       "      <td>0.192083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostR</th>\n",
       "      <td>11.078984</td>\n",
       "      <td>0.120717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            MSE          \n",
       "                           mean       std\n",
       "model                                    \n",
       "ExplainableBoostingR   9.165603  0.183922\n",
       "GradientBoostingR      9.192149  0.197236\n",
       "RFR                    9.201881  0.170242\n",
       "XGBoostR               9.209953  0.192083\n",
       "AdaBoostR             11.078984  0.120717"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average MSE over 5-fold cross-validation\n",
    "results.groupby('model').agg({'MSE':['mean','std']}).sort_values(by=('MSE', 'mean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters selection of EBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward analysis\n",
    "DBAC~ {activity i's duration} i=1,...,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "y=data.loc[:,'duration']\n",
    "X=data.loc[:,['duration1','duration2', 'duration3','duration4', 'duration5','duration6', 'duration7','duration8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inner_bags': 6, 'max_leaves': 2}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ExplainableBoostingRegressor\n",
    "# https://interpret.ml/docs/python/api/ExplainableBoostingRegressor.html\n",
    "mdr = GridSearchCV(ExplainableBoostingRegressor(),\n",
    "        param_grid={\"inner_bags\": np.linspace(0,6,3).astype('int'),\n",
    "                    \"max_leaves\": np.linspace(1,3,3).astype('int')},n_jobs=6)    \n",
    "\n",
    "mdr.fit(X, y)\n",
    "mdr.best_params_ # 'inner_bags': 6, 'mx_leaves': 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward analysis\n",
    "DBAC~ {activity i's duration at 75%EV} i=1,...,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "y=data.loc[:,'duration']\n",
    "X=data.loc[:,['duration@1','duration@2', 'duration@3','duration@4', 'duration@5','duration@6', 'duration@7','duration@8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inner_bags': 3, 'max_leaves': 2}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ExplainableBoostingRegressor\n",
    "# https://interpret.ml/docs/python/api/ExplainableBoostingRegressor.html\n",
    "mdr = GridSearchCV(ExplainableBoostingRegressor(),\n",
    "        param_grid={\"inner_bags\": np.linspace(0,6,3).astype('int'),\n",
    "                    \"max_leaves\": np.linspace(1,3,3).astype('int')},n_jobs=6)    \n",
    "\n",
    "mdr.fit(X, y)\n",
    "mdr.best_params_ # 'inner_bags': 3, 'mx_leaves': 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward analysis\n",
    "TB~ {activity i's duration at 75%EV} i=1,...,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "y=data.loc[:,'duration@']\n",
    "X=data.loc[:,['duration@1','duration@2', 'duration@3','duration@4', 'duration@5','duration@6', 'duration@7','duration@8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inner_bags': 0, 'max_leaves': 3}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ExplainableBoostingRegressor\n",
    "# https://interpret.ml/docs/python/api/ExplainableBoostingRegressor.html\n",
    "mdr = GridSearchCV(ExplainableBoostingRegressor(),\n",
    "        param_grid={\"inner_bags\": np.linspace(0,6,3).astype('int'),\n",
    "                    \"max_leaves\": np.linspace(1,3,3).astype('int')},n_jobs=6)    \n",
    "\n",
    "mdr.fit(X, y)\n",
    "mdr.best_params_ # 'inner_bags': 0, 'mx_leaves': 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier models\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from interpret.glassbox import ExplainableBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes \n",
    "# Expected time of the project 13\n",
    "data['delay']=data['duration']>13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data.loc[:,'delay']\n",
    "X=data.loc[:,['duration@1','duration@2', 'duration@3','duration@4', 'duration@5','duration@6', 'duration@7','duration@8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer kfolds\n",
    "kfold =StratifiedKFold(n_splits=5, random_state=seed,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results\n",
    "results = pd.DataFrame([['none',0,0]],columns=['model','kf','Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 0...\n",
      "running 1...\n",
      "running 2...\n",
      "running 3...\n",
      "running 4...\n"
     ]
    }
   ],
   "source": [
    "# ExplainableBoostingClassifier\n",
    "# https://interpret.ml/docs/python/api/ExplainableBoostingClassifier.html\n",
    "model='ExplainableBoostingC'\n",
    "k=0\n",
    "for train_index, test_index in kfold.split(X,y):\n",
    "  print('running %i...'%k)\n",
    "  # parameter optimization in the inner folds\n",
    "    # n_estimators: number of gradient boosted trees\n",
    "    # max_depth: maximum tree depth for base learners\n",
    "  mdc = GridSearchCV(ExplainableBoostingClassifier(),\n",
    "            param_grid={\"inner_bags\": np.linspace(0,6,3).astype('int'),\n",
    "                        \"max_leaves\": np.linspace(1,3,3).astype('int')},n_jobs=6)    \n",
    "  mdc.fit(X.iloc[train_index,:], y.iloc[train_index])\n",
    "  \n",
    "  # score of the best model in the outer fold\n",
    "  results = pd.concat([results, pd.DataFrame([[model,k, accuracy_score(y.iloc[test_index],mdc.best_estimator_.predict(X.iloc[test_index,:]))]],columns=['model','kf','Accuracy'])],ignore_index=True)\n",
    "  k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('./data/classification_ebm_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 0...\n",
      "running 1...\n",
      "running 2...\n",
      "running 3...\n",
      "running 4...\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "model='RFC'\n",
    "k=0\n",
    "for train_index, test_index in kfold.split(X,y):\n",
    "  print('running %i...'%k)\n",
    "  # parameter optimization in the inner folds\n",
    "    # n_estimators: number of trees\n",
    "    # max_depth of the trees\n",
    "  mdc = GridSearchCV(RandomForestClassifier(),\n",
    "                    param_grid={\"n_estimators\": np.linspace(100,1000,5).astype('int'), \n",
    "                            \"max_depth\": np.linspace(1,10,5).astype('int')},\n",
    "                    n_jobs=6)  \n",
    "  mdc.fit(X.iloc[train_index,:], y.iloc[train_index])\n",
    "  \n",
    "  # score of the best model in the outer fold\n",
    "  results = pd.concat([results, pd.DataFrame([[model,k, accuracy_score(y.iloc[test_index],mdc.best_estimator_.predict(X.iloc[test_index,:]))]],columns=['model','kf','Accuracy'])],ignore_index=True)\n",
    "  k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('./data/classification_rf_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 0...\n",
      "running 1...\n",
      "running 2...\n",
      "running 3...\n",
      "running 4...\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "model='GradientBoostingC'\n",
    "k=0\n",
    "for train_index, test_index in kfold.split(X,y):\n",
    "  print('running %i...'%k)\n",
    "  # parameter optimization in the inner folds\n",
    "    # n_estimators: number of  boosting stages\n",
    "    # max_depth of the regression estimators\n",
    "  mdc = GridSearchCV(GradientBoostingClassifier(),\n",
    "                    param_grid={\"n_estimators\": np.linspace(100,1000,5).astype('int'),  \n",
    "                                \"max_depth\": np.linspace(1,10,5).astype('int')},\n",
    "                    n_jobs=6)  \n",
    "  mdc.fit(X.iloc[train_index,:], y.iloc[train_index])\n",
    "  \n",
    "  # score of the best model in the outer fold\n",
    "  results = pd.concat([results, pd.DataFrame([[model,k, accuracy_score(y.iloc[test_index],mdc.best_estimator_.predict(X.iloc[test_index,:]))]],columns=['model','kf','Accuracy'])],ignore_index=True)\n",
    "  k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('./data/classification_gb_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 0...\n",
      "running 1...\n",
      "running 2...\n",
      "running 3...\n",
      "running 4...\n"
     ]
    }
   ],
   "source": [
    "# AdaBoostClassifier\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "model='AdaBoostC'\n",
    "\n",
    "k=0\n",
    "for train_index, test_index in kfold.split(X,y):\n",
    "  print('running %i...'%k)\n",
    "  # parameter optimization in the inner folds\n",
    "    # n_estimators: maximum number of estimators at which boosting is terminated\n",
    "  mdc = GridSearchCV(AdaBoostClassifier(),\n",
    "                    param_grid={\"n_estimators\": np.linspace(100,1000,5).astype('int'),\n",
    "                                \"learning_rate\": np.linspace(0.1,1,5)},\n",
    "                    n_jobs=6)\n",
    "  mdc.fit(X.iloc[train_index,:], y.iloc[train_index])\n",
    "  \n",
    "  # score of the best model in the outer fold\n",
    "  results = pd.concat([results, pd.DataFrame([[model,k, accuracy_score(y.iloc[test_index],mdc.best_estimator_.predict(X.iloc[test_index,:]))]],columns=['model','kf','Accuracy'])],ignore_index=True)  \n",
    "  k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('./data/classification_ab_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 0...\n",
      "running 1...\n",
      "running 2...\n",
      "running 3...\n",
      "running 4...\n"
     ]
    }
   ],
   "source": [
    "# XGBClassifier\n",
    "# https://xgboost.readthedocs.io/en/stable/python/python_api.html#module-xgboost.sklearn\n",
    "model='XGBoostC'\n",
    "k=0\n",
    "for train_index, test_index in kfold.split(X,y):\n",
    "  print('running %i...'%k)\n",
    "  # parameter optimization in the inner folds\n",
    "    # n_estimators: number of gradient boosted trees\n",
    "    # max_depth: maximum tree depth for base learners\n",
    "  mdc = GridSearchCV(XGBClassifier(verbosity = 0),\n",
    "                    param_grid={\"n_estimators\": np.linspace(100,1000,5).astype('int'),  \n",
    "                                \"max_depth\": np.linspace(1,10,5).astype('int')},\n",
    "                    n_jobs=6)    \n",
    "  mdc.fit(X.iloc[train_index,:], y.iloc[train_index])\n",
    "  \n",
    "  # score of the best model in the outer fold\n",
    "  results = pd.concat([results, pd.DataFrame([[model,k, accuracy_score(y.iloc[test_index],mdc.best_estimator_.predict(X.iloc[test_index,:]))]],columns=['model','kf','Accuracy'])],ignore_index=True)\n",
    "  k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('./data/classification_xgb_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results.drop(results[results.model=='none'].index,inplace=True)\n",
    "results.reset_index(inplace=True,drop=True)\n",
    "results.to_csv('./data/classification_model_selection_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "results=pd.read_csv('./data/classification_model_selection_results.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExplainableBoostingC</th>\n",
       "      <td>0.85846</td>\n",
       "      <td>0.002716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingC</th>\n",
       "      <td>0.85706</td>\n",
       "      <td>0.003024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>0.85704</td>\n",
       "      <td>0.001481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoostC</th>\n",
       "      <td>0.85700</td>\n",
       "      <td>0.002124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostC</th>\n",
       "      <td>0.85466</td>\n",
       "      <td>0.002503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy          \n",
       "                         mean       std\n",
       "model                                  \n",
       "ExplainableBoostingC  0.85846  0.002716\n",
       "GradientBoostingC     0.85706  0.003024\n",
       "RFC                   0.85704  0.001481\n",
       "XGBoostC              0.85700  0.002124\n",
       "AdaBoostC             0.85466  0.002503"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average Accuracy over 5-fold cross-validation\n",
    "results.groupby('model').agg({'Accuracy':['mean','std']}).sort_values(by=('Accuracy', 'mean'),ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward analysis\n",
    "C_dbac~ {activity i's duration at 75%EV} i=1,...,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data.loc[:,'delay']\n",
    "X=data.loc[:,['duration@1','duration@2', 'duration@3','duration@4', 'duration@5','duration@6', 'duration@7','duration@8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inner_bags': 6, 'max_leaves': 2}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ExplainableBoostingClassifier\n",
    "# https://interpret.ml/docs/python/api/ExplainableBoostingClassifier.html\n",
    "mdc = GridSearchCV(ExplainableBoostingClassifier(),\n",
    "            param_grid={\"inner_bags\": np.linspace(0,6,3).astype('int'),\n",
    "                        \"max_leaves\": np.linspace(1,3,3).astype('int')},n_jobs=6)    \n",
    "\n",
    "mdc.fit(X, y)\n",
    "mdc.best_params_ # {'inner_bags': 6, 'max_leaves': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward analysis\n",
    "C_tb~ {activity i's duration at 75%EV} i=1,...,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected time of the project at 75%EV 9.1763\n",
    "data['delay@']=data['duration@']>9.1763"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data.loc[:,'delay@']\n",
    "X=data.loc[:,['duration@1','duration@2', 'duration@3','duration@4', 'duration@5','duration@6', 'duration@7','duration@8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inner_bags': 6, 'max_leaves': 3}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ExplainableBoostingClassifier\n",
    "# https://interpret.ml/docs/python/api/ExplainableBoostingClassifier.html\n",
    "mdc = GridSearchCV(ExplainableBoostingClassifier(),\n",
    "            param_grid={\"inner_bags\": np.linspace(0,6,3).astype('int'),\n",
    "                        \"max_leaves\": np.linspace(1,3,3).astype('int')},n_jobs=6)    \n",
    "mdc.fit(X, y)\n",
    "mdc.best_params_ # {'inner_bags': 6, 'max_leaves': 3}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nchenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a99b9f778b7a026bd5c86bd94be6744eb13aba0a0ce78769fbbfa49d88ffc1f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
